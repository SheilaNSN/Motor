{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "927TEwq67PTs"
      },
      "source": [
        "**Elaboração de um novo modelo de classificação com base nas informações de usuários avaliados pelo INCT-DD**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OGoavUM67PU5"
      },
      "outputs": [],
      "source": [
        "#Carrega as bibliotecas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, matthews_corrcoef, mean_squared_error, r2_score, mean_absolute_percentage_error, max_error, explained_variance_score, median_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, classification_report\n",
        "import math\n",
        "import statistics\n",
        "import datetime\n",
        "import pytz\n",
        "import pickle\n",
        "## NLTK (biblioteca para processamento de linguagem natural)\n",
        "import nltk\n",
        "from nltk.stem.rslp import RSLPStemmer ##http://www.nltk.org/howto/portuguese_en.html\n",
        "\n",
        "#O primeiro uso exige obter os pacotes adicionais da biblioteca descomentando as linhas a seguir\n",
        "#Instala os pacotes de termos do nltk (apenas na primeira vez)\n",
        "#nltk.download()\n",
        "#nltk.download('rslp')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZ_Qu_k17PVd"
      },
      "source": [
        "**O novo modelo de classificação de bots foi construído com base nos usuários manualmente avaliados pelo INCT-DD**\n",
        "\n",
        "Essa escolha foi tomada considerando que esse conjunto de dados é o melhor que se possui quanto à real possibilidade de um usuário do Twitter ser um bot, não existindo bases de avaliação dentro da realidade brasileira (especialmente quanto ao português), bem como atualizadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvfZaKog7PWe"
      },
      "outputs": [],
      "source": [
        "#Busca os dados dos usuários avaliados\n",
        "datafile_users = \"data/sample2/inct_users.csv\"\n",
        "df_users = pd.read_csv(datafile_users, header = 0)\n",
        "\n",
        "#Preenche os valores NaN con 0 apenas para avaliação geral\n",
        "df_users = df_users.fillna(0)\n",
        "print(len(df_users))\n",
        "#Apresenta o total de usuários avaliados\n",
        "df_users.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPfPDzhC7PWh"
      },
      "source": [
        "**No novo modelos são consideradas apenas as informações associadas como \"É bot?\" de respotas \"Sim\" ou \"Não\"**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eq_Lgd8k7PWh"
      },
      "outputs": [],
      "source": [
        "#Busca a classificação do INCT-DD\n",
        "datafile_handles = \"data/sample1/handles_inct.csv\" #A classificação é a mesma da sample1\n",
        "df_handles = pd.read_csv(datafile_handles, header = 0)\n",
        "print(len(df_handles))\n",
        "df_handles['É Bot?'].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67UOpnjs7PW7"
      },
      "source": [
        "**As mais recentes postagens dos usuários foram consideradas como um atributo do modelo**\n",
        "\n",
        "Para a classificação dos usuários, o novo modelo inclui atributos relacionados com as postagens dos usuários, na tentativa de extrair informação mais atualizada e dinâmica de sua atuação. Entretanto, os textos das postagens foram utilizados unificando seus conteúdos e extraindo informações representativas, tais como os termos mais recorrentemente utilizados, diferença no tempo das postagens e repostagens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7B5REjz7PW9"
      },
      "outputs": [],
      "source": [
        "#Recupera os últimos twittes\n",
        "datafile_timeline = \"data/sample2/inct_timelines.csv\"\n",
        "df_timeline = pd.read_csv(datafile_timeline, header = 0)\n",
        "print(len(df_timeline))\n",
        "df_timeline.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22j96U407PXY"
      },
      "source": [
        "Aplica um pré-processamento nos dados para unificar a informação da postagens se tratar de um retweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3AwE-XL7PXd"
      },
      "outputs": [],
      "source": [
        "#identifica os formatos existentes\n",
        "df_timeline['tweet_is_retweet'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "re-rhDW-7PXh"
      },
      "outputs": [],
      "source": [
        "df_timeline['retweet_tratado'] = df_timeline['tweet_is_retweet'].apply(lambda x: \"sim\" if (x == 'True' or x == True) else \"não\")\n",
        "df_timeline['retweet_tratado'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fL-c0XVU7PXj"
      },
      "outputs": [],
      "source": [
        "#Necessário reverificar no texto do tweet por RT @, pois o campo tweet_is_retweet falha em algumas situações não identificadas\n",
        "#Parecem ser os RT com comentários adicionais\n",
        "#for tweet in df_timeline['retweet_tratado', 'tweet_text']:\n",
        "#    if tweet['retweet_tratado'] == 'não':\n",
        "#        if tweet['tweet_text'].find(\"RT @\") != -1:\n",
        "#            tweet['retweet_tratado'] = 'sim'\n",
        "#len(df_timeline)\n",
        "#for i in range(len(df_timeline)):\n",
        "#    if df_timeline.iloc[i]['retweet_tratado'] == 'não':\n",
        "#        if df_timeline.iloc[i]['tweet_text'].find(\"RT @\") != -1:\n",
        "#            df_timeline.iloc[i]['retweet_tratado']  = 'sim'\n",
        "df_timeline['tweet_com_rt_tratado'] = df_timeline['tweet_text'].apply(lambda x: \"sim\" if x.find(\"RT @\") != -1 else \"não\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZ4MtB6m7PXk"
      },
      "outputs": [],
      "source": [
        "#Combina em uma única coluna as informações de retweets e tweets com RT comentados\n",
        "def reune_rt(retweet,rt):\n",
        "    if retweet == 'sim' or rt == 'sim':\n",
        "        return 'sim'\n",
        "    else:\n",
        "        return 'não'\n",
        "\n",
        "df_timeline['retweet_e_tweet_com_rt_tratado'] = df_timeline.apply(lambda x: reune_rt(x.retweet_tratado, x.tweet_com_rt_tratado), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spf9TLKO7PXk"
      },
      "outputs": [],
      "source": [
        "df_timeline[df_timeline[\"retweet_e_tweet_com_rt_tratado\"] == 'sim']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mjegEAd7PXl"
      },
      "source": [
        "Extrai a diferença em segundos entre as postagens do usuário"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K92q8TWf7PXz"
      },
      "outputs": [],
      "source": [
        "#Incluir uma dedida da distancia temporal entre twittes (mediana e mínimo)\n",
        "df_handles['Tempo mediano'] = np.array(len(df_handles))\n",
        "df_handles['Tempo menor']   = np.array(len(df_handles))\n",
        "iuser = 0\n",
        "for user in df_handles['handle']:\n",
        "    df_temp = df_timeline[df_timeline['tweet_author'] == user]\n",
        "    itweet = 0\n",
        "    menor = 100000\n",
        "    difs = list()\n",
        "    tweet_date_prev = None\n",
        "    for tweet in df_temp['tweet_created_at']:\n",
        "        tweet_date = pd.to_datetime(pd.to_datetime(tweet).strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
        "        if itweet > 0:\n",
        "            dif = (tweet_date_prev - tweet_date).seconds\n",
        "            if dif < menor:\n",
        "                menor = dif\n",
        "            difs.append(dif)\n",
        "        else:\n",
        "            tweet_date_prev = tweet_date\n",
        "        tweet_date_prev = tweet_date\n",
        "        itweet += 1\n",
        "    if len(difs) > 0:\n",
        "        mediana = statistics.median(difs)\n",
        "    else:\n",
        "        mediana = 1000\n",
        "    print(user + ' - ' + str(menor) + ' - ' + str(mediana)+'\\n')\n",
        "    df_handles['Tempo mediano'][iuser] = mediana\n",
        "    df_handles['Tempo menor'][iuser]   = menor\n",
        "    iuser += 1\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdiIU8SN7PX7"
      },
      "source": [
        "**Os dados inicialmente tratados são reunidos com a classificação dada pelo INCT-DD**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGxdQHEc7PYA"
      },
      "outputs": [],
      "source": [
        "#Reune os dados do usuário com a classificação\n",
        "df_result_merge = pd.merge(df_handles, df_users, on=['handle'])\n",
        "print(len(df_result_merge))\n",
        "df_result_merge.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YymPdmg7PYB"
      },
      "source": [
        "**Os dados das postagens foram reunidos para a extração de informações representativas**\n",
        "\n",
        "Para viabilizar o treinamento do modelo, os dados por postagens foram convertidos em conjuntos por usuário (autor do tweet, e a representação foi dada por informações sumarizadas ou probabilísticas, por exemplo, as hashtags mais utilizadas ou o percentual de postagens realizadas a partir do Android, iPhone ou Web."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxBZ_e6X7PYB"
      },
      "outputs": [],
      "source": [
        "#Reune todos os tweets de um mesmo autor em um único texto, separando apenas por vírgula\n",
        "df_result_text = df_timeline.groupby('tweet_author').agg({'tweet_text':lambda col: ', '.join(col)}).reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHMF91LM7PYC"
      },
      "outputs": [],
      "source": [
        "#Reune todos as hashtags utilizadas por um mesmo autor em um único texto, separando apenas por vírgula\n",
        "df_result_hashtags = df_timeline.groupby('tweet_author').agg({'tweet_hashtags':lambda col: ', '.join(col)}).reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQZ_f7oC7PYC"
      },
      "outputs": [],
      "source": [
        "#Reune a informação de fonte de todos os tweets de um mesmo autor em um único texto, separando apenas por vírgula\n",
        "df_result_source = df_timeline.groupby('tweet_author').agg({'tweet_source':lambda col: ', '.join(col)}).reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WTpPHsX7PYD"
      },
      "outputs": [],
      "source": [
        "#Reune as informações de twettes que são retweets\n",
        "df_result_retweet = df_timeline.groupby('tweet_author').agg({'retweet_tratado':lambda col: ', '.join(col)}).reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuuiKwzX7PYE"
      },
      "outputs": [],
      "source": [
        "#Reune as informações de twettes com RT\n",
        "df_result_tweet_com_rt = df_timeline.groupby('tweet_author').agg({'tweet_com_rt_tratado':lambda col: ', '.join(col)}).reset_index()\n",
        "df_result_tweet_com_rt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EB4BHxuh7PYE"
      },
      "outputs": [],
      "source": [
        "#Reune as informações da junção de retweets e tweets com rt\n",
        "df_result_retweet_e_tweet_com_rt = df_timeline.groupby('tweet_author').agg({'retweet_e_tweet_com_rt_tratado':lambda col: ', '.join(col)}).reset_index()\n",
        "df_result_retweet_e_tweet_com_rt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VN_2YdJO7PYF"
      },
      "outputs": [],
      "source": [
        "#Reune os dados (merge) do usuários, suas avaliações com texto dos tweets, as hashtags, as fontes e os retweets\n",
        "df_result_merge = pd.merge(df_handles, df_users, on=['handle'])\n",
        "df_result_merge = pd.merge(df_result_merge,df_result_text, left_on=['handle'], right_on=['tweet_author'])\n",
        "df_result_merge = pd.merge(df_result_merge,df_result_hashtags, left_on=['handle'], right_on=['tweet_author'])\n",
        "df_result_merge = pd.merge(df_result_merge,df_result_source, left_on=['handle'], right_on=['tweet_author'])\n",
        "df_result_merge = pd.merge(df_result_merge,df_result_retweet, left_on=['handle'], right_on=['tweet_author'])\n",
        "df_result_merge = pd.merge(df_result_merge,df_result_tweet_com_rt, left_on=['handle'], right_on=['tweet_author'])\n",
        "df_result_merge = pd.merge(df_result_merge,df_result_retweet_e_tweet_com_rt, left_on=['handle'], right_on=['tweet_author'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbQoqVOM7PYF"
      },
      "outputs": [],
      "source": [
        "#Exibe parte dos resultados da junção (nem todos os usuários ainda estão ativos e número de amostras diminui)\n",
        "print(len(df_result_merge))\n",
        "df_result_merge.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Rzz51Yb7PYn"
      },
      "source": [
        "**A classificação dos usuários foi padronizada para 0 - Não Bot e 1 - Bot**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nu_KagQy7PYo"
      },
      "outputs": [],
      "source": [
        "#Padroniza a saída da classificação do INCT-DD para bot e monta o conjunto Y\n",
        "df = df_result_merge\n",
        "y = df['É Bot?'].apply(lambda x: 1 if (x == 'Sim' or x == 'sim') else 0)\n",
        "y.reset_index(drop=True, inplace=True)\n",
        "y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhTcXPFl7PZ9"
      },
      "outputs": [],
      "source": [
        "##Seleciona as colunas para o conjunto X\n",
        "#feature_cols = ['tweet_text'] #,'tweet_source','tweet_hashtags'\n",
        "#x = df['tweet_text']\n",
        "#x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "II8v8qh47PaJ"
      },
      "source": [
        "** [Classficando apenas pelo texto dos Twittes (NLTK)] **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R56IWyK97PaJ"
      },
      "outputs": [],
      "source": [
        "##Prepara o conjunto de dados para treinamento e teste\n",
        "#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-16M7lu7PaK"
      },
      "outputs": [],
      "source": [
        "##Método para vetorizar e contabilizar os termos\n",
        "stemmer = nltk.stem.RSLPStemmer()\n",
        "class StemmedCountVectorizerRSLPS(CountVectorizer):\n",
        "    def build_analyzer(self):\n",
        "        analyzer = super(StemmedCountVectorizerRSLPS, self).build_analyzer()\n",
        "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])\n",
        "stemmed_count_vect = StemmedCountVectorizerRSLPS(stop_words=nltk.corpus.stopwords.words('portuguese'))\n",
        "tfidf_transformer = TfidfTransformer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddV1zRsG7PaK"
      },
      "outputs": [],
      "source": [
        "##Pipeline para extrair as informaçoes e classificar com base no texto (pode ser usado ANN ou MNB [MultinomialNB(fit_prior=False)])\n",
        "#text_mnb_stemmed = Pipeline([('vect', stemmed_count_vect),\n",
        "#                      ('tfidf', TfidfTransformer()),\n",
        "#                      ('mnb', MLPClassifier(random_state=1, max_iter=600, activation='relu',solver='adam')),\n",
        "#])\n",
        "#text_mnb_stemmed = text_mnb_stemmed.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qu7cniNg7PaL"
      },
      "outputs": [],
      "source": [
        "#text_mnb_stemmed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5qJUc6P7PaM"
      },
      "outputs": [],
      "source": [
        "##Avalia a classificação\n",
        "#predicted_mnb_stemmed = text_mnb_stemmed.predict(x_test)\n",
        "#np.mean(predicted_mnb_stemmed == y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfNX7De17PaN"
      },
      "source": [
        "**Os atributos do treinamentos envolvem diversos fatores**\n",
        "\n",
        "Uma das etapas mais critícas da modelagem é a definição dos atributos que representam o cenário real, nesse sentido foram incluídas o máximo de variáveis que pudessem representar um usuário e suas atividades na rede, desde o tamanho do login escolhido até o tempo mínimo entre suas postagens. Na sequência são realizadas as atividades de extração, tratamento e junção dessas informações como atributos do conjunto de treinamento do modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S14BUskc7PaN"
      },
      "outputs": [],
      "source": [
        "df.columns #df é o conjunto completo de dados, já com os twittes-hashtags-sources-retweets em campos únicos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRJ9OC-L7PaO"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIpaAdBJ7PaR"
      },
      "source": [
        "De todo os conjuntos de informações disponíveis não foram selecionados aquelas que não poderiam ser automaticamente extraídos dos perfis e atividades dos usuários na rede. Portanto, as classificações como \"comportamento agressivo?\", \"Parece só Retweetar?\", entre outras, não foram incluídos no conjunto de treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUNcPqXG7PaR"
      },
      "outputs": [],
      "source": [
        "feature_cols = ['followers_count', 'friends_count', 'Tempo mediano', 'Tempo menor']\n",
        "x = df[feature_cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWvbWTpz7PaS"
      },
      "outputs": [],
      "source": [
        "##Converte os testos em frequências\n",
        "#st = stemmed_count_vect.fit_transform((df['tweet_text']))\n",
        "#tfidf_transformer = TfidfTransformer()\n",
        "#x_tfidf = tfidf_transformer.fit_transform(st)\n",
        "#x_tfidf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5mSMm6e7PaS"
      },
      "outputs": [],
      "source": [
        "##Inclui as frequências no conjunto x\n",
        "#x_tfidf.shape\n",
        "#x.join(pd.DataFrame(x_tfidf.todense()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfC_1g4Q7PaS"
      },
      "outputs": [],
      "source": [
        "len(df['tweet_hashtags'][7].replace(\"[\",\"\").replace(\"]\",\"\").replace(\", \\'\",\"$\").split(\"$\"))\n",
        "len(df['tweet_hashtags'][7].split(\", [\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Y-eXlzn7PaT"
      },
      "outputs": [],
      "source": [
        "#Inclui os quantitativos de hashtages utilizadas (e a mediana por postagem)\n",
        "\n",
        "qtd_hashtags = df['tweet_hashtags'].apply(lambda x: len(x.replace(\"[\",\"\").replace(\"]\",\"\").replace(\", \\'\",\"$\").split(\"$\")))\n",
        "x['Quantidade hashtags'] = np.array(list(qtd_hashtags))\n",
        "qtd_hashtags_media = df['tweet_hashtags'].apply(lambda x: len(x.replace(\"[\",\"\").replace(\"]\",\"\").replace(\", \\'\",\"$\").split(\"$\"))/len(x.split(\", [\")))\n",
        "x['Quantidade hashtags media'] = np.array(list(qtd_hashtags_media))\n",
        "\n",
        "x.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xuvrquau7Pak"
      },
      "outputs": [],
      "source": [
        "#Inclui o número de dígitos no nome\n",
        "username_digitos = df['handle'].apply(lambda x: sum(c.isdigit() for c in str(x)) ) \n",
        "x['Digitos no username'] = np.array(list(username_digitos))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOc5_N3U7Pal"
      },
      "outputs": [],
      "source": [
        "#O tamanho do nome e do login\n",
        "tam_username = df['handle'].apply(lambda x: len(str(x)))\n",
        "tam_nome = df['name'].apply(lambda x: len(str(x)))\n",
        "x['Tamanho do username'] = np.array(list(tam_username))\n",
        "x['Tamanho do nome'] = np.array(list(tam_nome))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2XcPEXL7Pao"
      },
      "outputs": [],
      "source": [
        "x.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CH_gBd2d7Pap"
      },
      "source": [
        "A fonte do tweet foi considera importante informação, considerando que automações de postagens possam ser facilitadas a partir da versão Web ou que possa existir algum padrão no uso das diferentes fontes. Sendo assim, forneceu-se ao métodos a informação percentual da origem das postagens do mesmo usuário, seja Android, iPhone ou Web."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PA-nQtX77Pap"
      },
      "outputs": [],
      "source": [
        "#Calcula a quantidade de twittes por fontes\n",
        "fonte_android = df['tweet_source'].apply(lambda x: str(x).count('Twitter for Android') )\n",
        "fonte_iphone = df['tweet_source'].apply(lambda x: str(x).count('Twitter for iPhone') )\n",
        "fonte_web = df['tweet_source'].apply(lambda x: str(x).count('Twitter Web App') )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qb1zOUtd7Paq"
      },
      "outputs": [],
      "source": [
        "fonte_soma = fonte_android + fonte_iphone + fonte_web\n",
        "fonte_soma = fonte_soma.apply(lambda x: 1 if x <= 0 else x )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3jisk_x7Paq"
      },
      "outputs": [],
      "source": [
        "#Calcula o percentual por usuário\n",
        "fonte_android = fonte_android/fonte_soma\n",
        "fonte_iphone = fonte_iphone/fonte_soma\n",
        "fonte_web = fonte_web/fonte_soma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v77zkFO47Par"
      },
      "outputs": [],
      "source": [
        "x['Fonte de Android'] = np.array(list(fonte_android))\n",
        "x['Fonte de iPhone'] = np.array(list(fonte_iphone))\n",
        "x['Fonte de Web'] = np.array(list(fonte_web))\n",
        "x = x.fillna(0)\n",
        "x.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1t4Vo327PbA"
      },
      "outputs": [],
      "source": [
        "#Avaliação geral das diferentes fontes\n",
        "x['Fonte de Android'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTexF4tw7PbE"
      },
      "outputs": [],
      "source": [
        "x['Fonte de iPhone'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jERckDT47PbF"
      },
      "outputs": [],
      "source": [
        "x['Fonte de Web'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCzvN_cT7PbF"
      },
      "outputs": [],
      "source": [
        "#Inclui a informação do retweet\n",
        "df['retweet_tratado'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbrN4jhA7PbF"
      },
      "outputs": [],
      "source": [
        "retweet_tratado = df['retweet_tratado'].apply(lambda x: str(x).count('sim')/len(x.split(\",\")))\n",
        "x['retweet_tratado_media'] = np.array(list(retweet_tratado))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrW_OslD7PbG"
      },
      "outputs": [],
      "source": [
        "tweet_com_rt = df['tweet_com_rt_tratado'].apply(lambda x: str(x).count('sim')/len(x.split(\",\")))\n",
        "x['tweet_com_rt_tratado_media'] = np.array(list(tweet_com_rt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7oE8hWj7PbG"
      },
      "outputs": [],
      "source": [
        "retweet_e_tweet_com_rt = df['retweet_e_tweet_com_rt_tratado'].apply(lambda x: str(x).count('sim')/len(x.split(\",\")))\n",
        "x['retweet_e_tweet_com_rt_tratado_media'] = np.array(list(retweet_e_tweet_com_rt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlytV5I07PbH"
      },
      "outputs": [],
      "source": [
        "x_novo = x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaCHESA_7PbH"
      },
      "outputs": [],
      "source": [
        "##Inclui os textos dos twittes (NLTK)\n",
        "#st = stemmed_count_vect.fit_transform((df['tweet_text']))\n",
        "#tfidf_transformer = TfidfTransformer()\n",
        "#x_tfidf = tfidf_transformer.fit_transform(st)\n",
        "#x_tfidf\n",
        "#x_novo = x.join(pd.DataFrame(x_tfidf.todense()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yW7Y3Av7PbI"
      },
      "outputs": [],
      "source": [
        "x_novo.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOQRSvsp7PbI"
      },
      "outputs": [],
      "source": [
        "x_novo.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJ-JpYRj7PbJ"
      },
      "source": [
        "**Com o primeiro conjunto de atributos formado é possível separar o conjunto de dados em treinamento e teste para a elaboração do modelo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLasoR-y7PbJ"
      },
      "outputs": [],
      "source": [
        "#Cria um modelo de classificação para o conjunto completo\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_novo, y, test_size=0.3, random_state=1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "228hA5FY7PbK"
      },
      "outputs": [],
      "source": [
        "classifier = RandomForestClassifier(n_jobs=3, random_state=1, n_estimators=100)\n",
        "classifier = classifier.fit(x_train,y_train)\n",
        "y_pred = classifier.predict(x_test)\n",
        "np.mean(y_pred == y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEK_BZOF7PbK"
      },
      "outputs": [],
      "source": [
        "##Seleciona os atributos mais \"importantes\"\n",
        "#x_new = SelectKBest(chi2, k=20).fit_transform(x_novo, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4FJwF877PbL"
      },
      "outputs": [],
      "source": [
        "#x_train, x_test, y_train, y_test = train_test_split(x_new, y, test_size=0.3, random_state=1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPXmF5Os7PbL"
      },
      "outputs": [],
      "source": [
        "classifier = RandomForestClassifier(n_jobs=3, random_state=1, n_estimators=100)\n",
        "classifier = classifier.fit(x_train,y_train)\n",
        "y_pred = classifier.predict(x_test)\n",
        "mean = np.mean(y_pred == y_test)\n",
        "balanced = balanced_accuracy_score(y_test, y_pred)\n",
        "print (\"Mean: \" + str(mean) + \" | Balanced accuracy: \" + str(balanced))\n",
        "confusion_matrix(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UILmgJj67PbL"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1bcM8gn7PbM"
      },
      "outputs": [],
      "source": [
        "#Classificação com RNA\n",
        "classifier = MLPClassifier(max_iter=1200, random_state=1, activation='tanh', solver='adam') #activation: logistic, relu, tanh, identity | solver: lbfgs, sgd, adam\n",
        "classifier = classifier.fit(x_train,y_train)\n",
        "y_pred = classifier.predict(x_test)\n",
        "mean = np.mean(y_pred == y_test)\n",
        "balanced = balanced_accuracy_score(y_test, y_pred)\n",
        "print (\"Mean: \" + str(mean) + \" | Balanced accuracy: \" + str(balanced))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjOyunTq7PbM"
      },
      "source": [
        "**Informações de trend topics**\n",
        "\n",
        "Outra informação que se mostrou de relevância ao longo do trabalho de modelagem foi a relação das postagens de bots com as menções e hashtags listadas nos mais atuais 'trend topics', ou seja, o aparente uso de termos altamente utilizados no momento para possivelmente alavancar a visibilidade da postagem.\n",
        "\n",
        "Para averiguar essa possibilidade, um sistema de monitoramento dos tópicos mais mencionados foi criado e cada postagem coletada do usuário foi confrontado com os 'trend topics' do período mais próximo. Esse confrontamento gerou um percentual de uso desses tópicos nas postagens dos usuários."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjMETYvz7PbM"
      },
      "outputs": [],
      "source": [
        "#Busca os dados de todas as trending topics recuperadas\n",
        "datafile_trends = \"data/sample2/trends_dataclips_qijpjdyxutqsnrteglrjtwjhdjja.csv\"\n",
        "df_trends = pd.read_csv(datafile_trends, header = 0)\n",
        "#Preenche os valores NaN con 0 apenas para avaliação geral\n",
        "df_trends = df_trends.fillna(0)\n",
        "print(len(df_trends))\n",
        "df_trends.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQDa2xma7PbN"
      },
      "source": [
        "Entre os passos de tratamentos dos dados das \"trend topics\" está o ajuste dos padrões de data e hora dos registros, tanto dos tópicos monitorados quanto dos próprios tweets.\n",
        "A seguir são extraídas as datas dos tweets no formato yyyy-mm-dd, dentro da conversão nos próximos trechos foi também necessário ajustar o \"timezone\" desses dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvo7m1Z57PbN"
      },
      "outputs": [],
      "source": [
        "#Inclui um percentual de trending topics utilizado por tweet\n",
        "#Para tweet, busca pelos trending topics imediatamente anteriores\n",
        "df_timeline['Numero de trendings'] = np.array(len(df_timeline))\n",
        "df_timeline['Numero de trendings'] = 0\n",
        "df_trends['Trend Date Time Convertido'] = np.array(len(df_trends))\n",
        "\n",
        "itrend = 0\n",
        "for x in df_trends['trend_date_time']:\n",
        "    df_trends['Trend Date Time Convertido'][itrend] = pd.to_datetime(x).strftime(\"%Y-%m-%d\")\n",
        "    itrend += 1\n",
        "\n",
        "df_trends.head()   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvfW-ED67PcR"
      },
      "source": [
        "O relacionamento dos trends e dos tweets foi realizado percorrendo todos os trends armazenados para cada tweet em data anterior ao do tweet e, para cada trend nessa condição, verificou-se no texto do tweet a presença de trendings. Caso esteja presente acumulou-se essa ocorrência, finalizando com a ocorrência de uso de uma trend por cada tweet.\n",
        "Este trecho demanda de melhorias em desempenho e na inclusão de restrições que reduzam o tempo de ocorrência da trend para mais próximo do tweet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgVi3zKt7PcS"
      },
      "outputs": [],
      "source": [
        "itweet = 0\n",
        "for tweet in df_timeline['tweet_created_at']:\n",
        "    tweet_date = pd.to_datetime(pd.to_datetime(tweet).strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
        "    df_temp = df_trends[df_trends['Trend Date Time Convertido'] == tweet_date.strftime(\"%Y-%m-%d\")] \n",
        "        \n",
        "    itrend = 0\n",
        "    for trend in df_temp['Trend Date Time Convertido']:\n",
        "        trend_date = pd.to_datetime(pd.to_datetime(trend).strftime(\"%Y-%m-%d\"))\n",
        "        if trend_date <= tweet_date.tz_convert(None):\n",
        "            if df_timeline['tweet_text'][itweet].find(df_trends['trend'][itrend]) != -1: \n",
        "                df_timeline['Numero de trendings'][itweet] = df_timeline['Numero de trendings'][itweet] + 1\n",
        "        itrend += 1\n",
        "    print(itweet)    \n",
        "    itweet += 1     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9c9u0JF7PcS"
      },
      "source": [
        "Para cada tweet foi armazenados o número de trend topics encontrado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pymA6N8B7PcT"
      },
      "outputs": [],
      "source": [
        "df_timeline[df_timeline['Numero de trendings'] > 0].describe()\n",
        "df_timeline['Numero de trendings'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFqhw2vK7PcU"
      },
      "outputs": [],
      "source": [
        "df_timeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soED7UhC7PcW"
      },
      "source": [
        "As quantidades de trendings utilizadas em cada tweet foram agrupados por autor (usuário), assim foram incluídos na base de treinamento o número de trendings utilizadas, a média de trendings por tweet desse autor e o número máximo de trendings usado em um mesmo tweet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEPw3rsG7PcW"
      },
      "outputs": [],
      "source": [
        "#Reune as informações de trends nos tweets por author\n",
        "df_result_trend = df_timeline.groupby('tweet_author').agg({'Numero de trendings':lambda col: sum(col)/len(col)}).reset_index()\n",
        "df_result_trend_max = df_timeline.groupby('tweet_author').agg({'Numero de trendings':lambda col: max(col)}).reset_index()\n",
        "df_result_trend['trends_media'] = df_result_trend['Numero de trendings']\n",
        "df_result_trend_max['trends_max'] = df_result_trend_max['Numero de trendings']\n",
        "df_result_trend_max"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yIhJN157PcX"
      },
      "outputs": [],
      "source": [
        "df_handles.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61vUOvkv7PcX"
      },
      "outputs": [],
      "source": [
        "df_trends.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7KTGW067Pcc"
      },
      "outputs": [],
      "source": [
        "trends_unique = df_trends.trend.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZjAYFoT7Pcc"
      },
      "outputs": [],
      "source": [
        "df_result_merge.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foLxqn2N7Pcd"
      },
      "source": [
        "Os valores referentes aos trendings do usuário são reunidos (\"merged\") com os dados gerais do usuário"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TF2JPt_v7Pcd"
      },
      "outputs": [],
      "source": [
        "df_result_merge = pd.merge(df_result_merge,df_result_trend, left_on=['handle'], right_on=['tweet_author'])\n",
        "df_result_merge = pd.merge(df_result_merge,df_result_trend_max, left_on=['handle'], right_on=['tweet_author'])\n",
        "df_result_merge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_feEFebz7Pce"
      },
      "outputs": [],
      "source": [
        "#df_result_merge_trend = df_result_merge\n",
        "df_result_merge['qtdtrends'] = np.array(list(tam_username))\n",
        "\n",
        "ttemp = 0\n",
        "iuser = 0\n",
        "for user in df_result_merge.tweet_text:\n",
        "    for trend in trends_unique:\n",
        "        if user.find(trend) != -1:\n",
        "            ttemp = ttemp + 1\n",
        "    print(str(ttemp) + \" - \" + str(iuser) + \" | \" + str((iuser/len(df_result_merge.tweet_text))*100) + \"%\")\n",
        "    df_result_merge['qtdtrends'][iuser] = ttemp\n",
        "    iuser = iuser + 1\n",
        "    ttemp = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJDOc98z7Pce"
      },
      "outputs": [],
      "source": [
        "df_result_merge.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nET-Blqw7Pcg"
      },
      "outputs": [],
      "source": [
        "x_novo_trend = x_novo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eMgG6MM7Pco"
      },
      "source": [
        "Por fim os dados do monitoramento das trendings são incluídos na base de treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTQ4k4dd7Pcq"
      },
      "outputs": [],
      "source": [
        "x_novo_trend['qtdtrends'] = df_result_merge['qtdtrends']\n",
        "x_novo_trend['trends_media'] = df_result_merge['trends_media']\n",
        "x_novo_trend['trends_max'] = df_result_merge['trends_max']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yB6MFwry7Pcq"
      },
      "outputs": [],
      "source": [
        "x_novo_trend.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EC-qwVCp7Pcs"
      },
      "source": [
        "**Conjuntos de treinamento e teste**\n",
        "\n",
        "Os dados reunidos para geração dos modelos são, então, separados em dados de treinamento e teste para a aplicação dos métodos de aprendizagem de máquina - em especial Random Florest, Redes neuronais artificiais e Gradient Boosting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJ7anM2u7Pct"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_novo_trend, y, test_size=0.3, random_state=1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_wKSNl87Pct"
      },
      "outputs": [],
      "source": [
        "classifier = RandomForestClassifier(n_jobs=3, random_state=1, n_estimators=100)\n",
        "classifier = classifier.fit(x_train,y_train)\n",
        "y_pred = classifier.predict(x_test)\n",
        "mean = np.mean(y_pred == y_test)\n",
        "balanced = balanced_accuracy_score(y_test, y_pred)\n",
        "print (\"Mean: \" + str(mean) + \" | Balanced accuracy: \" + str(balanced))\n",
        "print(\"Score: \" + str(classifier.score(x_test, y_test)))\n",
        "confusion_matrix(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wN8RH137Pcu"
      },
      "outputs": [],
      "source": [
        "classifier = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=1)\n",
        "classifier = classifier.fit(x_train,y_train)\n",
        "y_pred = classifier.predict(x_test)\n",
        "mean = np.mean(y_pred == y_test)\n",
        "balanced = balanced_accuracy_score(y_test, y_pred)\n",
        "print (\"Mean: \" + str(mean) + \" | Balanced accuracy: \" + str(balanced))\n",
        "print(\"Score: \" + str(classifier.score(x_test, y_test)))\n",
        "confusion_matrix(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6q8T1eVN7Pcu"
      },
      "outputs": [],
      "source": [
        "importances = classifier.feature_importances_\n",
        "\n",
        "indices = np.argsort(importances)\n",
        "\n",
        "fig, ax = plt.subplots(figsize =(10, 6))\n",
        "ax.barh(range(len(importances)), importances[indices])\n",
        "ax.set_yticks(range(len(importances)))\n",
        "_ = ax.set_yticklabels(np.array(x_novo_trend.columns)[indices])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDsHAAjJ7Pcv"
      },
      "source": [
        "**Resultados**\n",
        "\n",
        "Os resultados ainda demandam de maior avaliação, especialmente com a variação da semente aleatória para os cortes do conjunto de treinamento e para a aplicação dos métodos. Ainda nesse sentido, demanda-se ainda da seleção de modelos baseada na otimização dos hiperparâmetros dos métodos aplicados.\n",
        "\n",
        "Mesmo com essas demandas, observa-se uma acurácia aproximada de 74% para os métodos (e aproximadamente 70% ao considerar-se o desbalanceamento da base). Valor considerado bom, dado o complexo cenário tratado. \n",
        "\n",
        "Importante ponto a ser destacado que o valor da acurácia baseia-se também em um ponto de corte da consistência da classificação, a qual pode variar en 0.0 e 1.0, valores que atrelam-se à probabilidade da classificação, em que por padrão adota-se o corte em 0.5, apesar da aplicação pode gerar um intervalo mais restrito, deslocando a média/mediana das predições. Dito isso e considerando que não deva ser utilizado apenas o corte \"bruto\" de bot ou não bot, a associação dessa probabilidade permite melhor compreensão do \"risco\" do usuário ser efetivamente um bot, bem como permite um deslocamento do rigor dessa classificação. \n",
        "\n",
        "Os trechos a seguir avaliam a acurácia considerando a mediana das predições como corte, bem como a comparação dos valores preditos nos grupos de usuários previamente (manualmente) classificados como bot ou não, no qual verifica-se uma clara separação dos valores preditos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NEkQQDa7Pcv"
      },
      "outputs": [],
      "source": [
        "#x_new_trend = SelectKBest(chi2, k=10).fit_transform(x_novo_trend, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJ_XeqO77Pcw"
      },
      "outputs": [],
      "source": [
        "#x_train, x_test, y_train, y_test = train_test_split(x_new_trend, y, test_size=0.3, random_state=1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxfF7UNU7Pcw"
      },
      "outputs": [],
      "source": [
        "#classifier = RandomForestClassifier(n_jobs=3, random_state=1, n_estimators=100)\n",
        "#classifier = classifier.fit(x_train,y_train)\n",
        "#y_pred = classifier.predict(x_test)\n",
        "#mean = np.mean(y_pred == y_test)\n",
        "#balanced = balanced_accuracy_score(y_test, y_pred)\n",
        "#print (\"Mean: \" + str(mean) + \" | Balanced accuracy: \" + str(balanced))\n",
        "#confusion_matrix(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5IW6XgG7Pcx"
      },
      "outputs": [],
      "source": [
        "#x_new_trend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlK4E1Vx7Pcx"
      },
      "outputs": [],
      "source": [
        "#confusion_matrix(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAib0Qvn7Pcy"
      },
      "outputs": [],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jqMEB4G7Pcz"
      },
      "outputs": [],
      "source": [
        "classifier.predict_proba(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mL9uaCAB7Pcz"
      },
      "outputs": [],
      "source": [
        "predicted_proba = classifier.predict_proba(x_test)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-uewhvYK7Pc0"
      },
      "outputs": [],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6Ga31Gu7Pc0"
      },
      "outputs": [],
      "source": [
        "np.median(classifier.predict_proba(x_test)[:,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxR6Z-G57Pc0"
      },
      "outputs": [],
      "source": [
        "threshold = 0.6\n",
        "predicted = (classifier.predict_proba(x_test)[:,1] >= threshold).astype(bool)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SM0LXs8j7Pc-"
      },
      "outputs": [],
      "source": [
        "np.mean(predicted == y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3Z3ERJ17Pc_"
      },
      "outputs": [],
      "source": [
        "x_test_geral = x_test\n",
        "dtf = [x_test, x_train]\n",
        "x_test_geral = pd.concat(dtf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMkSPGqW7Pc_"
      },
      "outputs": [],
      "source": [
        "print(len(x_test_geral))\n",
        "y_test_temp = y_test\n",
        "y_test_temp.reset_index(drop=True, inplace=True)\n",
        "y_test_temp[y_test_temp == 1].index\n",
        "res_geral = classifier.predict_proba(x_test_geral)[y_test_temp.index,1]\n",
        "res_sim = classifier.predict_proba(x_test_geral)[y_test_temp[y_test_temp == 1].index,1]\n",
        "res_nao = classifier.predict_proba(x_test_geral)[y_test_temp[y_test_temp == 0].index,1]\n",
        "\n",
        "np.median(res_sim)\n",
        "np.median(res_nao)\n",
        "bplots = plt.boxplot([res_geral, res_nao, res_sim],  vert = 1, patch_artist = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooat69Jp7PdA"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame({\"Não\": res_nao}).describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IR4OBscx7PdT"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame({\"Sim\": res_sim}).describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgmDjE2N7PdT"
      },
      "source": [
        "**Comparação com as predições do Botometer**\n",
        "\n",
        "Visando a avaliar a qualidade da classificação dos modelos gerados, os mesmos usuários passaram pela avaliação da ferramenta Botometer, já bem conhecida e amplamente utilizada (apesar de sua aplicação com enfoque nas publicações em Inglês)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOnWWiNK7PdT"
      },
      "outputs": [],
      "source": [
        "#Lê os dados da aplicação do botometer\n",
        "#Busca os dados dos usuários avaliados\n",
        "datafile_botometer = \"data/handles_inct.csv\"\n",
        "df_botometer = pd.read_csv(datafile_botometer, header = 0)\n",
        "#Preenche os valores NaN con 0 apenas para avaliação geral\n",
        "df_botometer = df_botometer.fillna(0)\n",
        "print(len(df_botometer))\n",
        "df_botometer.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6PvzqFh7PdU"
      },
      "outputs": [],
      "source": [
        "#Avalia os resultados do botometer\n",
        "a = len(df_botometer['analise_botometer'])\n",
        "b = len(df_botometer[(df_botometer['É Bot?'] == 'não') | (df_botometer['É Bot?'] == 'Não')]['analise_botometer'])\n",
        "c = len(df_botometer[(df_botometer['É Bot?'] == 'sim') | (df_botometer['É Bot?'] == 'Sim')]['analise_botometer'])\n",
        "print(\" \" + str(a) + \" = \" + str(b) + \" + \" + str(c))\n",
        "botometer_geral = df_botometer['analise_botometer']\n",
        "botometer_nao   = df_botometer[(df_botometer['É Bot?'] == 'não') | (df_botometer['É Bot?'] == 'Não')]['analise_botometer']\n",
        "botometer_sim   = df_botometer[(df_botometer['É Bot?'] == 'sim') | (df_botometer['É Bot?'] == 'Sim')]['analise_botometer']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYws_LmR7PdU"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize =(20, 10)) #(11, 6)\n",
        "bplots = plt.boxplot([botometer_geral/5, botometer_nao/5, botometer_sim/5, res_geral, res_nao, res_sim],  vert = 1, patch_artist = False)\n",
        "colors = ['blue', 'green', 'red', 'lightblue', 'lightgreen', 'pink']\n",
        "c = 0\n",
        "for i, bplot in enumerate(bplots['boxes']):\n",
        "    bplot.set(color=colors[c], linewidth=3)\n",
        "    c += 1\n",
        "    \n",
        "colorss = ['blue','blue', 'green', 'green', 'red', 'red', 'lightblue', 'lightblue', 'lightgreen', 'lightgreen', 'pink', 'pink' ]    \n",
        "c3 = 0\n",
        "for cap in bplots['caps']:\n",
        "    cap.set(color=colorss[c3], linewidth=3)\n",
        "    c3 +=1\n",
        "\n",
        "plt.title(\"Boxplot da avaliação do Botometer e do novo modelo Pegabot para os dados avaiados no INCT-DD\", loc=\"center\", fontsize=18)\n",
        "plt.xlabel(\"Agrupados por: (1) Botometer Geral; (2) Botometer apenas considerados não bots; (3) Botometer apenas considerados bots; (4) Novo Pegabot Geral; (5) Novo Pegabot apenas considerados não bots; (6) Novo Pegabot apenas considerados bots\")\n",
        "plt.ylabel(\"Avaliação do Botometer\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wp7FZ3_l7PdV"
      },
      "outputs": [],
      "source": [
        "import scipy\n",
        "scipy.stats.kruskal(botometer_geral,  botometer_nao,botometer_sim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzlyGFWb7PdV"
      },
      "outputs": [],
      "source": [
        "scipy.stats.kruskal(res_geral,  res_nao,res_sim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZzrLEd37PdV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}